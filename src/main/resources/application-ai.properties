# Local Ollama configuration for chat and embedding models
spring.ai.model.chat=ollama
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=qwen2.5:3b
spring.ai.ollama.chat.options.temperature=0.1
spring.ai.ollama.embedding.model=bge-m3:567m
spring.ai.ollama.init.pull-model-strategy=when_missing
#
# PGVector configuration
spring.ai.vectorstore.type=pgvector
spring.ai.vectorstore.pgvector.id-type=bigserial
spring.ai.vectorstore.pgvector.table-name=history_vector
spring.ai.vectorstore.pgvector.dimensions=1024